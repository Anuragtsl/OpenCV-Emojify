# OpenCV-Emojify

In this deep learning project, I've classified human facial expressions to filter and map corresponding emojis or avatars.

With advancements in [Computer Vision]() and [Deep learning](), it is now possible to detect human emotions from images.

Emojis or avatars are ways to indicate nonverbal cues. These cues have become an essential part of online chatting, product review, brand emotion, and many more. 

It also lead to increasing data science research dedicated to emoji-driven storytelling.

***Follow [code](https://github.com/Anuragtsl/OpenCV-Emojify/blob/main/train.py) for more!!***

# About the Dataset

The FER2013 dataset ( facial expression recognition) consists of 48x48 pixel grayscale face images. 

The images are centered and occupy an equal amount of space. This dataset consist of facial emotions of following categories:

0:angry

1:disgust

2:feat

3:happy

4:sad

5:surprise

6:natural

**Download the [dataset](https://github.com/Anuragtsl/OpenCV-Emojify/blob/main/Dataset.txt) from here!!**

# Preview

![Image1]()

![Image2]()


#Njoy!!
